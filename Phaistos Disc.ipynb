{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phaistos Disc Side A\n",
      " 𐇑𐇛𐇜𐇐𐇡\n",
      " 𐇧𐇷𐇛 𐇬𐇼𐇖\n",
      " 𐇬𐇬𐇱 𐇑𐇛𐇓𐇷𐇰 𐇪𐇼𐇖𐇛 𐇪𐇻𐇗 𐇑𐇛𐇕𐇡 𐇮𐇩𐇲 𐇑𐇛𐇸𐇢𐇲 𐇐𐇸𐇷𐇖 𐇑𐇛𐇯𐇦𐇵\n",
      " 𐇶𐇚 𐇑𐇪𐇨𐇙𐇦𐇡 𐇫𐇐\n",
      " 𐇑𐇛𐇮𐇩\n",
      " 𐇑𐇛𐇪𐇪𐇲𐇴𐇤 𐇰𐇦 𐇑𐇛𐇮𐇩\n",
      " 𐇑𐇪𐇨𐇙𐇦𐇡 𐇫𐇐\n",
      " 𐇑𐇛𐇮𐇩\n",
      " 𐇑𐇛𐇪𐇝𐇯𐇡𐇪 𐇕𐇡𐇠𐇢 𐇮𐇩𐇛 𐇑𐇛𐇜𐇐 𐇦𐇢𐇲\n",
      " 𐇙𐇒𐇵 𐇑𐇛𐇪𐇪𐇲𐇴𐇤 𐇜𐇐 𐇙𐇒𐇵 \n",
      "\n",
      "\n",
      "Phaistos Disc Side B\n",
      " 𐇑𐇛𐇥𐇷𐇖 𐇪𐇼𐇖𐇲 𐇑𐇴𐇦𐇔\n",
      " 𐇥𐇨𐇪 𐇰𐇧𐇣𐇛 𐇟𐇦𐇡𐇺\n",
      " 𐇜𐇐𐇶𐇰 𐇞𐇖𐇜𐇐𐇡 𐇥𐇴𐇹𐇨 𐇖𐇧𐇷𐇲 𐇑𐇩𐇳𐇷 𐇪𐇨𐇵𐇐 𐇬𐇧𐇧𐇣𐇲 𐇟𐇝𐇡 𐇬𐇰𐇐 𐇕𐇲𐇯𐇶𐇰 𐇑𐇘𐇪𐇐 𐇬𐇳𐇖𐇗\n",
      " 𐇬𐇗𐇜 𐇬𐇼𐇖\n",
      " 𐇥𐇬𐇳𐇖𐇗\n",
      " 𐇪𐇱𐇦𐇨 𐇖𐇡𐇲 𐇖𐇼𐇖\n",
      " 𐇖𐇦𐇡𐇧 𐇥𐇬𐇳𐇖𐇗\n",
      " 𐇘𐇭𐇶𐇡𐇖 𐇑𐇕𐇲𐇦𐇖 𐇬𐇱𐇦𐇨 𐇼𐇖\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import itertools as it\n",
    "\n",
    "pd_inscription_a = (\"𐇑𐇛𐇜𐇐𐇡𐇽|𐇧𐇷𐇛|𐇬𐇼𐇖𐇽|𐇬𐇬𐇱|𐇑𐇛𐇓𐇷𐇰|𐇪𐇼𐇖𐇛|𐇪𐇻𐇗|𐇑𐇛𐇕𐇡|𐇮𐇩𐇲|\"\n",
    "                \"𐇑𐇛𐇸𐇢𐇲|𐇐𐇸𐇷𐇖|𐇑𐇛𐇯𐇦𐇵𐇽|𐇶𐇚|𐇑𐇪𐇨𐇙𐇦𐇡|𐇫𐇐𐇽|𐇑𐇛𐇮𐇩𐇽|𐇑𐇛𐇪𐇪𐇲𐇴𐇤|𐇰𐇦|\"\n",
    "                \"𐇑𐇛𐇮𐇩𐇽|𐇑𐇪𐇨𐇙𐇦𐇡|𐇫𐇐𐇽|𐇑𐇛𐇮𐇩𐇽|𐇑𐇛𐇪𐇝𐇯𐇡𐇪|𐇕𐇡𐇠𐇢|𐇮𐇩𐇛|𐇑𐇛𐇜𐇐|𐇦𐇢𐇲𐇽|𐇙𐇒𐇵|𐇑𐇛𐇪𐇪𐇲𐇴𐇤|𐇜𐇐|𐇙𐇒𐇵|\")\n",
    "pd_words_a = pd_inscription_a.split('|')\n",
    "\n",
    "pd_inscription_b = (\"𐇑𐇛𐇥𐇷𐇖|𐇪𐇼𐇖𐇲|𐇑𐇴𐇦𐇔𐇽|𐇥𐇨𐇪|𐇰𐇧𐇣𐇛|𐇟𐇦𐇡𐇺𐇽|𐇜𐇐𐇶𐇰|𐇞𐇖𐇜𐇐𐇡|𐇥𐇴𐇹𐇨|\"\n",
    "                    \"𐇖𐇧𐇷𐇲|𐇑𐇩𐇳𐇷|𐇪𐇨𐇵𐇐|𐇬𐇧𐇧𐇣𐇲|𐇟𐇝𐇡|𐇬𐇰𐇐|𐇕𐇲𐇯𐇶𐇰|𐇑𐇘𐇪𐇐|𐇬𐇳\"\n",
    "                    \"𐇖𐇗𐇽|𐇬𐇗𐇜|𐇬𐇼𐇖𐇽|𐇥𐇬𐇳𐇖𐇗𐇽|𐇪𐇱𐇦𐇨|𐇖𐇡𐇲|𐇖𐇼𐇖𐇽|𐇖𐇦𐇡𐇧|𐇥𐇬𐇳𐇖𐇗𐇽|𐇘𐇭𐇶𐇡𐇖|𐇑𐇕𐇲𐇦𐇖|𐇬𐇱𐇦𐇨|𐇼𐇖𐇽|\")\n",
    "pd_words_b = pd_inscription_b.split('|')\n",
    "\n",
    "pd_inscription = pd_inscription_a + pd_inscription_b\n",
    "pd_words = pd_inscription.replace('𐇽','').split('|')\n",
    "\n",
    "print(\"Phaistos Disc Side A\")\n",
    "print(' ' + ' '.join(w.replace('𐇽','\\n') for w in pd_words_a))\n",
    "\n",
    "print('\\n')\n",
    "print(\"Phaistos Disc Side B\")\n",
    "print(' ' + ' '.join(w.replace('𐇽','\\n') for w in pd_words_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '𐇑𐇛𐇜𐇐𐇡𐇽'),\n",
       " (1, '𐇧𐇷𐇛'),\n",
       " (2, '𐇬𐇼𐇖𐇽'),\n",
       " (3, '𐇬𐇬𐇱'),\n",
       " (4, '𐇑𐇛𐇓𐇷𐇰'),\n",
       " (5, '𐇪𐇼𐇖𐇛'),\n",
       " (6, '𐇪𐇻𐇗'),\n",
       " (7, '𐇑𐇛𐇕𐇡'),\n",
       " (8, '𐇮𐇩𐇲'),\n",
       " (9, '𐇑𐇛𐇸𐇢𐇲'),\n",
       " (10, '𐇐𐇸𐇷𐇖'),\n",
       " (11, '𐇑𐇛𐇯𐇦𐇵𐇽'),\n",
       " (12, '𐇶𐇚'),\n",
       " (13, '𐇑𐇪𐇨𐇙𐇦𐇡'),\n",
       " (14, '𐇫𐇐𐇽'),\n",
       " (15, '𐇑𐇛𐇮𐇩𐇽'),\n",
       " (16, '𐇑𐇛𐇪𐇪𐇲𐇴𐇤'),\n",
       " (17, '𐇰𐇦'),\n",
       " (15, '𐇑𐇛𐇮𐇩𐇽'),\n",
       " (13, '𐇑𐇪𐇨𐇙𐇦𐇡'),\n",
       " (14, '𐇫𐇐𐇽'),\n",
       " (15, '𐇑𐇛𐇮𐇩𐇽'),\n",
       " (22, '𐇑𐇛𐇪𐇝𐇯𐇡𐇪'),\n",
       " (23, '𐇕𐇡𐇠𐇢'),\n",
       " (24, '𐇮𐇩𐇛'),\n",
       " (25, '𐇑𐇛𐇜𐇐'),\n",
       " (26, '𐇦𐇢𐇲𐇽'),\n",
       " (27, '𐇙𐇒𐇵'),\n",
       " (16, '𐇑𐇛𐇪𐇪𐇲𐇴𐇤'),\n",
       " (29, '𐇜𐇐'),\n",
       " (27, '𐇙𐇒𐇵'),\n",
       " (31, '𐇑𐇛𐇥𐇷𐇖'),\n",
       " (32, '𐇪𐇼𐇖𐇲'),\n",
       " (33, '𐇑𐇴𐇦𐇔𐇽'),\n",
       " (34, '𐇥𐇨𐇪'),\n",
       " (35, '𐇰𐇧𐇣𐇛'),\n",
       " (36, '𐇟𐇦𐇡𐇺𐇽'),\n",
       " (37, '𐇜𐇐𐇶𐇰'),\n",
       " (38, '𐇞𐇖𐇜𐇐𐇡'),\n",
       " (39, '𐇥𐇴𐇹𐇨'),\n",
       " (40, '𐇖𐇧𐇷𐇲'),\n",
       " (41, '𐇑𐇩𐇳𐇷'),\n",
       " (42, '𐇪𐇨𐇵𐇐'),\n",
       " (43, '𐇬𐇧𐇧𐇣𐇲'),\n",
       " (44, '𐇟𐇝𐇡'),\n",
       " (45, '𐇬𐇰𐇐'),\n",
       " (46, '𐇕𐇲𐇯𐇶𐇰'),\n",
       " (47, '𐇑𐇘𐇪𐇐'),\n",
       " (48, '𐇬𐇳𐇖𐇗𐇽'),\n",
       " (49, '𐇬𐇗𐇜'),\n",
       " (2, '𐇬𐇼𐇖𐇽'),\n",
       " (51, '𐇥𐇬𐇳𐇖𐇗𐇽'),\n",
       " (52, '𐇪𐇱𐇦𐇨'),\n",
       " (53, '𐇖𐇡𐇲'),\n",
       " (54, '𐇖𐇼𐇖𐇽'),\n",
       " (55, '𐇖𐇦𐇡𐇧'),\n",
       " (51, '𐇥𐇬𐇳𐇖𐇗𐇽'),\n",
       " (57, '𐇘𐇭𐇶𐇡𐇖'),\n",
       " (58, '𐇑𐇕𐇲𐇦𐇖'),\n",
       " (59, '𐇬𐇱𐇦𐇨'),\n",
       " (60, '𐇼𐇖𐇽'),\n",
       " (61, '')]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(pd_words.index(w), w) for w in pd_words]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " (13, '𐇑𐇪𐇨𐇙𐇦𐇡'),\n",
    " (14, '𐇫𐇐𐇽'),\n",
    "\n",
    " (15, '𐇑𐇛𐇮𐇩𐇽'),\n",
    " (16, '𐇑𐇛𐇪𐇪𐇲𐇴𐇤'),\n",
    " (17, '𐇰𐇦'),\n",
    " (15, '𐇑𐇛𐇮𐇩𐇽'),\n",
    "\n",
    " (13, '𐇑𐇪𐇨𐇙𐇦𐇡'),\n",
    " (14, '𐇫𐇐𐇽'),\n",
    " (15, '𐇑𐇛𐇮𐇩𐇽'),\n",
    " \n",
    " (22, '𐇑𐇛𐇪𐇝𐇯𐇡𐇪'),\n",
    " (23, '𐇕𐇡𐇠𐇢'),\n",
    " (24, '𐇮𐇩𐇛'),\n",
    " (25, '𐇑𐇛𐇜𐇐'),\n",
    " (26, '𐇦𐇢𐇲𐇽'),\n",
    "\n",
    " (27, '𐇙𐇒𐇵'),\n",
    " (16, '𐇑𐇛𐇪𐇪𐇲𐇴𐇤'),\n",
    " (29, '𐇜𐇐'),\n",
    " (27, '𐇙𐇒𐇵'),\n",
    "\n",
    " (31, '𐇑𐇛𐇥𐇷𐇖'),\n",
    " (32, '𐇪𐇼𐇖𐇲'),\n",
    " (33, '𐇑𐇴𐇦𐇔𐇽'),\n",
    " (34, '𐇥𐇨𐇪'),\n",
    " (35, '𐇰𐇧𐇣𐇛'),\n",
    "\n",
    "Arrangement of Side A showing its repetitive structure.\n",
    "\n",
    "Phaistos Disc Side A\n",
    " 𐇑𐇛𐇜𐇐𐇡 𐇧𐇷𐇛 𐇬𐇼𐇖 𐇬𐇬𐇱 \n",
    " \n",
    " 𐇑𐇛𐇓𐇷𐇰 𐇪𐇼𐇖𐇛 𐇪𐇻𐇗 \n",
    " 𐇑𐇛𐇕𐇡 𐇮𐇩𐇲 \n",
    " 𐇑𐇛𐇸𐇢𐇲 𐇐𐇸𐇷𐇖 \n",
    " \n",
    " 𐇑𐇛𐇯𐇦𐇵 \n",
    " 𐇶𐇚 \n",
    " 𐇑𐇪𐇨𐇙𐇦𐇡 \n",
    " 𐇫𐇐 \n",
    " 𐇑𐇛𐇮𐇩\n",
    " \n",
    " 𐇑𐇛𐇪𐇪𐇲𐇴𐇤\n",
    " 𐇰𐇦\n",
    " 𐇑𐇛𐇮𐇩\n",
    " \n",
    " 𐇑𐇪𐇨𐇙𐇦𐇡 𐇫𐇐 𐇑𐇛𐇮𐇩\n",
    " \n",
    " 𐇑𐇛𐇪𐇝𐇯𐇡𐇪 𐇕𐇡𐇠𐇢 𐇮𐇩𐇛 \n",
    " 𐇑𐇛𐇜𐇐 𐇦𐇢𐇲 𐇙𐇒𐇵 \n",
    " 𐇑𐇛𐇪𐇪𐇲𐇴𐇤 𐇜𐇐 𐇙𐇒𐇵 \n",
    "\n",
    "Phaistos Disc Side B\n",
    " 𐇑𐇛𐇥𐇷𐇖 𐇪𐇼𐇖𐇲 \n",
    " 𐇑𐇴𐇦𐇔\n",
    " 𐇥𐇨𐇪 𐇰𐇧𐇣𐇛 𐇟𐇦𐇡𐇺\n",
    " 𐇜𐇐𐇶𐇰 𐇞𐇖𐇜𐇐𐇡 𐇥𐇴𐇹𐇨 𐇖𐇧𐇷𐇲 \n",
    " 𐇑𐇩𐇳𐇷 𐇪𐇨𐇵𐇐 𐇬𐇧𐇧𐇣𐇲 𐇟𐇝𐇡 𐇬𐇰𐇐 𐇕𐇲𐇯𐇶𐇰 \n",
    " 𐇑𐇘𐇪𐇐 𐇬𐇳𐇖𐇗\n",
    " 𐇬𐇗𐇜 𐇬𐇼𐇖\n",
    " 𐇥𐇬𐇳𐇖𐇗\n",
    " 𐇪𐇱𐇦𐇨 𐇖𐇡𐇲 𐇖𐇼𐇖\n",
    " 𐇖𐇦𐇡𐇧 𐇥𐇬𐇳𐇖𐇗\n",
    " 𐇘𐇭𐇶𐇡𐇖 \n",
    " 𐇑𐇕𐇲𐇦𐇖 𐇬𐇱𐇦𐇨 𐇼𐇖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd_symbols = [\"𐇐\", \"𐇑\", \"𐇒\", \"𐇓\", \"𐇔\", \"𐇕\", \"𐇖\", \"𐇗\", \"𐇘\", \"𐇙\", \"𐇚\", \n",
    "    \"𐇛\", \"𐇜\", \"𐇝\", \"𐇞\", \"𐇟\", \"𐇠\", \"𐇡\", \"𐇢\", \"𐇣\", \"𐇤\", \"𐇥\", \"𐇦\", \"𐇧\", \"𐇨\", \"𐇩\", \"𐇪\", \"𐇫\", \"𐇬\", \"𐇭\", \"𐇮\", \"𐇯\"\n",
    "    , \"𐇰\", \"𐇱\", \"𐇲\", \"𐇳\", \"𐇴\", \"𐇵\", \"𐇶\", \"𐇷\", \"𐇸\", \"𐇹\", \"𐇺\", \"𐇻\", \"𐇼\"]\n",
    "\n",
    "la_symbols = [\"𐄂\", \"𐘀\", \"𐘁\", \"𐘂\", \"𐘃\", \"𐘄\", \"𐘅\", \"𐘆\", \"𐘇\", \"𐘈\", \"𐘉\", \"𐘊\", \"𐘋\", \"𐘌\", \"𐘍\", \"𐘎\", \n",
    "    \"𐘏\", \"𐘐\", \"𐘑\", \"𐘒\", \"𐘓\", \"𐘔\", \"𐘕\", \"𐘖\", \"𐘗\", \"𐘘\", \"𐘙\", \"𐘚\", \"𐘛\", \"𐘜\", \"𐘝\", \"𐘞\",\n",
    "    \"𐘟\", \"𐘠\", \"𐘡\", \"𐘢\", \"𐘣\", \"𐘤\", \"𐘥\", \"𐘦\", \"𐘧\", \"𐘨\", \"𐘩\", \"𐘪\", \"𐘫\", \"𐘬\", \"𐘭\", \"𐘮\",\n",
    "    \"𐘯\", \"𐘰\", \"𐘱\", \"𐘲\", \"𐘳\", \"𐘴\", \"𐘵\", \"𐘶\", \"𐘷\", \"𐘸\", \"𐘹\", \"𐘺\", \"𐘻\", \"𐘼\", \"𐘽\", \"𐘾\",\n",
    "    \"𐘿\", \"𐙀\", \"𐙁\", \"𐙂\", \"𐙃\", \"𐙄\", \"𐙅\", \"𐙆\", \"𐙇\", \"𐙈\", \"𐙉\", \"𐙊\", \"𐙋\", \"𐙌\", \"𐙍\", \n",
    "    \"𐙎\", \"𐙏\", \"𐙐\", \"𐙑\", \"𐙒\", \"𐙓\", \"𐙔\", \"𐙕\", \"𐙖\", \"𐙗\", \"𐙘\", \"𐙙\", \"𐙚\", \"𐙛\", \"𐙜\", \"𐙝\", \n",
    "    \"𐙞\", \"𐙟\", \"𐙠\", \"𐙡\", \"𐙢\", \"𐙣\", \"𐙤\", \"𐙥\", \"𐙦\", \"𐙧\", \"𐙨\", \"𐙩\", \"𐙪\", \"𐙫\", \"𐙬\", \"𐙭\",\n",
    "    \"𐙮\", \"𐙯\", \"𐙰\", \"𐙱\", \"𐙲\", \"𐙳\", \"𐙴\", \"𐙵\", \"𐙶\", \"𐙷\", \"𐙸\", \"𐙹\", \"𐙺\", \"𐙻\", \"𐙼\", \"𐙽\",\n",
    "    \"𐙾\", \"𐙿\", \"𐚀\", \"𐚁\", \"𐚂\", \"𐚃\", \"𐚄\", \"𐚅\", \"𐚆\", \"𐚇\", \"𐚈\", \"𐚉\", \"𐚊\", \"𐚋\", \"𐚌\", \"𐚍\",\n",
    "    \"𐚎\", \"𐚏\", \"𐚐\", \"𐚑\", \"𐚒\", \"𐚓\", \"𐚔\", \"𐚕\", \"𐚖\", \"𐚗\", \"𐚘\", \"𐚙\", \"𐚚\", \"𐚛\", \"𐚜\", \n",
    "    \"𐚝\", \"𐚞\", \"𐚟\", \"𐚠\", \"𐚡\", \"𐚢\", \"𐚣\", \"𐚤\", \"𐚥\", \"𐚦\", \"𐚧\", \"𐚨\", \"𐚩\", \"𐚪\", \"𐚫\", \"𐚬\", \n",
    "    \"𐚭\", \"𐚮\", \"𐚯\", \"𐚰\", \"𐚱\", \"𐚲\", \"𐚳\", \"𐚴\", \"𐚵\", \"𐚶\", \"𐚷\", \"𐚸\", \"𐚹\", \"𐚺\", \"𐚻\", \"𐚼\",\n",
    "    \"𐚽\", \"𐚾\", \"𐚿\", \"𐛀\", \"𐛁\", \"𐛂\", \"𐛃\", \"𐛄\", \"𐛅\", \"𐛆\", \"𐛇\", \"𐛈\", \"𐛉\", \"𐛊\", \"𐛋\", \"𐛌\",\n",
    "    \"𐛍\", \"𐛎\", \"𐛏\", \"𐛐\", \"𐛑\", \"𐛒\", \"𐛓\", \"𐛔\", \"𐛕\", \"𐛖\", \"𐛗\", \"𐛘\", \"𐛙\", \"𐛚\", \"𐛛\", \"𐛜\",\n",
    "    \"𐛝\", \"𐛞\", \"𐛟\", \"𐛠\", \"𐛡\", \"𐛢\", \"𐛣\", \"𐛤\", \"𐛥\", \"𐛦\", \"𐛧\", \"𐛨\", \"𐛩\", \"𐛪\", \"𐛫\", \n",
    "    \"𐛬\", \"𐛭\", \"𐛮\", \"𐛯\", \"𐛰\", \"𐛱\", \"𐛲\", \"𐛳\", \"𐛴\", \"𐛵\", \"𐛶\", \"𐛷\", \"𐛸\", \"𐛹\", \"𐛺\", \"𐛻\", \n",
    "    \"𐛼\", \"𐛽\", \"𐛾\", \"𐛿\", \"𐜀\", \"𐜁\", \"𐜂\", \"𐜃\", \"𐜄\", \"𐜅\", \"𐜆\", \"𐜇\", \"𐜈\", \"𐜉\", \"𐜊\", \"𐜋\",\n",
    "    \"𐜌\", \"𐜍\", \"𐜎\", \"𐜏\", \"𐜐\", \"𐜑\", \"𐜒\", \"𐜓\", \"𐜔\", \"𐜕\", \"𐜖\", \"𐜗\", \"𐜘\", \"𐜙\", \"𐜚\", \"𐜛\",\n",
    "    \"𐜜\", \"𐜝\", \"𐜞\", \"𐜟\", \"𐜠\", \"𐜡\", \"𐜢\", \"𐜣\", \"𐜤\", \"𐜥\", \"𐜦\", \"𐜧\", \"𐜨\", \"𐜩\", \"𐜪\", \"𐜫\",\n",
    "    \"𐜬\", \"𐜭\", \"𐜮\", \"𐜯\", \"𐜰\", \"𐜱\", \"𐜲\", \"𐜳\", \"𐜴\", \"𐜵\", \"𐜶\", \"𐝀\", \"𐝁\", \"𐝂\", \"𐝃\", \n",
    "    \"𐝄\", \"𐝅\", \"𐝆\", \"𐝇\", \"𐝈\", \"𐝉\", \"𐝊\", \"𐝋\", \"𐝌\", \"𐝍\", \"𐝎\", \"𐝏\", \"𐝐\", \"𐝑\", \"𐝒\", \"𐝓\", \n",
    "    \"𐝔\", \"𐝕\", \"𐝠\", \"𐝡\", \"𐝢\", \"𐝣\", \"𐝤\", \"𐝥\", \"𐝦\", \"𐝧\", \"𐝬\", \"𐝭\", \"𐝮\", \"𐝯\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('../210-wordtags.js')\n",
    "inscriptions = json.load(json_file)\n",
    "\n",
    "la_words = []\n",
    "for inscription in inscriptions:\n",
    "    word_tags = inscription[\"tagsForWords\"]\n",
    "\n",
    "    for index, word_tag in enumerate(word_tags):\n",
    "        tags = word_tag[\"tags\"]\n",
    "        if \"word\" not in tags:\n",
    "            continue\n",
    "        word = word_tag[\"word\"].replace('\\U0001076b', '')\n",
    "        if len(word) == 1:\n",
    "            continue\n",
    "        la_words.append(word)\n",
    "la_words = list(set(la_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear A:\n",
      "Unique bigrams 1170 Total bigrams 2036\n",
      "Unique symbols in bigrams 168\n",
      "\n",
      "Phaistos Disc:\n",
      "Unique bigrams 115 Total bigrams 180\n",
      "Unique symbols in bigrams 45\n",
      "\n",
      "Linear A:\n",
      "Unique trigrams 949 Total trigrams 1055\n",
      "Unique symbols in trigrams 123\n",
      "\n",
      "Phaistos Disc:\n",
      "Unique trigrams 93 Total trigrams 119\n",
      "Unique symbols in trigrams 43\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getNgrams(words, n):\n",
    "    ngrams = []\n",
    "    for word in words:\n",
    "        bg = [word[i:i+n] for i in range(0, len(word) - (n-1))]\n",
    "        if bg == \"𐘠𐘿\":\n",
    "            print(word)\n",
    "        ngrams.extend(bg)\n",
    "    return ngrams\n",
    "\n",
    "la_bigrams, pd_bigrams, pd_trigrams, la_trigrams = [], [], [], []\n",
    "ngram_infos = [\n",
    "    [la_bigrams, \"bi\", 2, la_words, \"Linear A\"],\n",
    "    [pd_bigrams, \"bi\", 2, pd_words, \"Phaistos Disc\"],\n",
    "    [la_trigrams, \"tri\", 3, la_words, \"Linear A\"],\n",
    "    [pd_trigrams, \"tri\", 3, pd_words, \"Phaistos Disc\"],\n",
    "]\n",
    "\n",
    "for ngram_info in ngram_infos:\n",
    "    ngram = ngram_info[0]\n",
    "    prefix = ngram_info[1]\n",
    "    n = ngram_info[2]\n",
    "    words = ngram_info[3]\n",
    "    name = ngram_info[4]\n",
    "    \n",
    "    ngram_info[0] = getNgrams(words, n)\n",
    "    ngram = ngram_info[0]\n",
    "    print(\"\\n\" + name + \":\")\n",
    "    print(\"Unique \" + prefix + \"grams\", len(set(ngram)), \n",
    "          \"Total \" + prefix + \"grams\", len(ngram))\n",
    "    print(\"Unique symbols in \" + prefix + \"grams\",\n",
    "          len(set(list(it.chain.from_iterable(ngram)))))\n",
    "\n",
    "la_bigrams = ngram_infos[0][0]\n",
    "pd_bigrams = ngram_infos[1][0]\n",
    "la_trigrams = ngram_infos[2][0]\n",
    "pd_trigrams = ngram_infos[3][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_trigrams_per_unique_word = [w[0] for w in set([(tr,w) for tr in pd_trigrams for w in pd_words if tr in w])]\n",
    "la_trigrams_per_unique_word = [w[0] for w in set([(tr,w) for tr in la_trigrams for w in la_words if tr in w])]\n",
    "pd_bigrams_per_unique_word = [w[0] for w in set([(tr,w) for tr in pd_bigrams for w in pd_words if tr in w])]\n",
    "la_bigrams_per_unique_word = [w[0] for w in set([(tr,w) for tr in la_bigrams for w in la_words if tr in w])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear A Trigrams appearing in more than one word\n",
      "{('𐙕𐘮𐘱', 2), ('𐘇𐘴𐘶', 2), ('𐘳𐘚𐙕', 4), ('𐘴𐘅𐘙', 2), ('𐘸𐘞𐘗', 2), ('𐘚𐙕𐘉', 2), ('𐘉𐘳𐘚', 2), ('𐙂𐘰𐘅', 2), ('𐘬𐘜𐘙', 2), ('𐘇𐘞𐘞', 4), ('𐘘𐘾𐘅', 2), ('𐙂𐘻𐘅', 3), ('𐙁𐘠𐘠', 2), ('𐘤𐘸𐘴', 2), ('𐘬𐘙𐘍', 2), ('𐘤𐘱𐘈', 2), ('𐘰𐘅𐘹', 2), ('𐘱𐘲𐙁', 2), ('𐘳𐘅𐘃', 2), ('𐘳𐘅𐘤', 2), ('𐘂𐘳𐘀', 2), ('𐘚𐘢𐘅', 2), ('𐘆𐘸𐘃', 4), ('𐙁𐘾𐘚', 2), ('𐘱𐘞𐘞', 4), ('𐘇𐘻𐘀', 2), ('𐘇𐘳𐘚', 3), ('𐘅𐘘𐘾', 3), ('𐘚𐘱𐘂', 2), ('𐘚𐘞𐘭', 2), ('𐘀𐙂𐘈', 2), ('𐘇𐘆𐘸', 2), ('𐘗𐘻𐘅', 2), ('𐘳𐘅𐘚', 2), ('𐘱𐘆𐘸', 3), ('𐘠𐘠𐙂', 2), ('𐘱𐘂𐘌', 2), ('𐘉𐘅𐘾', 5), ('𐘉𐘦𐘍', 2), ('𐘭𐘘𐙁', 2), ('𐘴𐘸𐘳', 2), ('𐘲𐘸𐘭', 2), ('𐘻𐘳𐘠', 2), ('𐙂𐘈𐘗', 2), ('𐘾𐘅𐘤', 5), ('𐘚𐘅𐘱', 2), ('𐘭𐘝𐘳', 2), ('𐘸𐘳𐘅', 2), ('𐘉𐘅𐘘', 3), ('𐘞𐘴𐘋', 4), ('𐘞𐘞𐘴', 7), ('𐘳𐘠𐘽', 2), ('𐘂𐘴𐘗', 2), ('𐙀𐘭𐘝', 2), ('𐘀𐙁𐘃', 2), ('𐘸𐘃𐘃', 3), ('𐘚𐙕𐘮', 2), ('𐘠𐘾𐘇', 2), ('𐘇𐘳𐘅', 3), ('𐘅𐘐𐘗', 2), ('𐘉𐘠𐘯', 3), ('𐘘𐙁𐘳', 2), ('𐘅𐘚𐙕', 2), ('𐘅𐘾𐘅', 4), ('𐘇𐘴𐘹', 2)}\n",
      "\n",
      "Phaistos Disc Trigrams appearing in more than one word\n",
      "{('𐇱𐇦𐇨', 2), ('𐇑𐇛𐇪', 2), ('𐇑𐇛𐇜', 2), ('𐇛𐇜𐇐', 2), ('𐇬𐇳𐇖', 2), ('𐇜𐇐𐇡', 2), ('𐇳𐇖𐇗', 2), ('𐇪𐇼𐇖', 2)}\n"
     ]
    }
   ],
   "source": [
    "#print([(tr, la_trigrams.count(tr)) for tr in la_trigrams if la_trigrams.count(tr) > 1])\n",
    "\n",
    "print(\"Linear A Trigrams appearing in more than one word\")\n",
    "print(set((tr, la_trigrams_per_unique_word.count(tr)) for tr in la_trigrams_per_unique_word \n",
    "       if la_trigrams_per_unique_word.count(tr) > 1))\n",
    "\n",
    "print(\"\\nPhaistos Disc Trigrams appearing in more than one word\")\n",
    "print(set((tr, pd_trigrams_per_unique_word.count(tr)) for tr in pd_trigrams_per_unique_word \n",
    "       if pd_trigrams_per_unique_word.count(tr) > 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear A Bigrams appearing in more than one word\n",
      "{('𐘭𐘘', 2), ('𐘇𐙕', 2), ('𐙚𐘹', 2), ('𐘱𐘬', 2), ('𐘀𐙁', 4), ('𐘐𐘗', 2), ('𐘴𐘠', 3), ('𐘴𐘋', 6), ('𐘂𐙂', 2), ('𐘂𐘴', 4), ('𐘱𐘙', 6), ('𐘇𐘻', 4), ('𐘱𐘘', 2), ('𐘾𐘅', 9), ('𐘸𐘝', 2), ('𐘘𐘣', 2), ('𐘂𐘈', 2), ('𐙂𐘂', 6), ('𐘴𐙁', 2), ('𐘀𐘲', 2), ('𐙁𐘁', 3), ('𐘀𐘃', 2), ('𐘸𐙠', 2), ('𐘇𐙂', 3), ('𐘇𐘀', 5), ('𐘙𐘷', 2), ('𐘞𐘞', 11), ('𐘾𐙂', 3), ('𐘶𐘃', 2), ('𐘢𐘅', 2), ('𐘚𐘢', 4), ('𐘉𐘪', 2), ('𐘂𐘱', 6), ('𐘀𐘘', 3), ('𐘾𐘚', 4), ('𐘠𐘯', 4), ('𐘚𐘱', 7), ('𐘬𐘙', 3), ('𐘸𐘀', 3), ('𐘴𐘃', 3), ('𐘭𐘳', 4), ('𐘃𐘱', 4), ('𐘚𐘤', 3), ('𐘣𐘃', 3), ('𐘳𐘭', 3), ('𐘀𐘸', 3), ('𐘐𐘹', 2), ('𐘠𐘾', 2), ('𐘴𐘅', 3), ('𐘍𐘤', 2), ('𐘾𐘉', 2), ('𐙂𐘀', 2), ('𐘻𐘀', 8), ('𐘮𐘱', 4), ('𐘻𐘳', 5), ('𐘴𐘶', 2), ('𐘨𐙂', 2), ('𐙂𐘁', 2), ('𐘅𐘾', 5), ('𐘗𐘃', 2), ('𐙹𐘆', 2), ('𐘌𐘸', 3), ('𐘃𐘚', 2), ('𐘳𐘝', 3), ('𐘙𐘶', 2), ('𐘌𐙈', 4), ('𐙂𐙁', 2), ('𐘀𐘾', 2), ('𐘠𐘅', 2), ('𐘹𐘘', 2), ('𐘝𐙁', 2), ('𐘱𐘂', 6), ('𐘸𐘁', 2), ('𐘠𐘠', 5), ('𐘻𐘠', 2), ('𐘵𐘻', 2), ('𐘇𐘆', 4), ('𐘌𐘌', 2), ('𐘾𐘈', 2), ('𐘞𐘗', 4), ('𐘤𐘆', 3), ('𐘢𐘳', 6), ('𐘾𐘞', 2), ('𐘀𐘻', 2), ('𐘸𐘅', 2), ('𐘭𐘲', 2), ('𐘆𐘾', 2), ('𐘳𐘚', 10), ('𐘞𐘕', 3), ('𐙂𐘙', 4), ('𐘇𐘲', 3), ('𐘱𐘠', 3), ('𐘸𐘃', 4), ('𐘉𐘠', 5), ('𐘹𐘲', 3), ('𐘳𐘯', 2), ('𐘇𐘈', 5), ('𐘴𐘱', 3), ('𐘃𐘃', 5), ('𐘙𐘱', 2), ('𐘾𐘳', 3), ('𐘜𐘙', 4), ('𐘚𐘥', 2), ('𐘠𐙁', 3), ('𐘺𐘇', 2), ('𐘆𐘅', 7), ('𐘚𐙕', 6), ('𐘅𐙁', 3), ('𐘸𐘘', 2), ('𐘙𐘚', 2), ('𐘇𐘗', 2), ('𐘉𐘦', 3), ('𐘾𐘘', 2), ('𐘀𐘅', 2), ('𐘉𐘳', 3), ('𐘭𐘅', 4), ('𐘴𐘸', 3), ('𐘙𐘻', 2), ('𐘳𐘠', 3), ('𐘬𐘝', 3), ('𐘗𐘠', 2), ('𐘇𐘹', 2), ('𐘤𐘬', 3), ('𐘆𐘸', 8), ('𐘆𐘴', 3), ('𐙁𐘾', 3), ('𐘬𐘴', 3), ('𐘾𐘯', 2), ('𐘌𐘘', 2), ('𐘂𐘀', 4), ('𐘆𐘆', 4), ('𐘹𐘐', 2), ('𐘻𐘅', 10), ('𐘱𐙂', 3), ('𐙁𐘤', 3), ('𐘯𐘣', 2), ('𐘚𐘻', 2), ('𐘬𐘭', 2), ('𐘹𐘻', 2), ('𐘾𐘴', 2), ('𐘮𐘢', 3), ('𐘘𐘱', 3), ('𐘄𐘚', 3), ('𐘾𐘤', 2), ('𐘱𐘤', 4), ('𐘠𐘝', 3), ('𐙁𐘶', 2), ('𐘙𐘁', 2), ('𐘲𐘾', 2), ('𐘤𐘴', 2), ('𐘙𐘍', 5), ('𐘤𐘀', 5), ('𐙀𐘝', 2), ('𐘃𐘭', 3), ('𐘬𐘮', 2), ('𐘲𐘜', 3), ('𐘀𐘁', 4), ('𐘸𐘸', 2), ('𐘌𐘙', 2), ('𐘅𐘃', 4), ('𐘞𐘽', 2), ('𐘤𐘃', 5), ('𐙁𐘗', 2), ('𐘠𐘽', 2), ('𐘇𐘬', 7), ('𐘚𐘈', 4), ('𐘾𐘇', 3), ('𐘳𐘴', 4), ('𐘸𐘭', 4), ('𐘂𐘭', 3), ('𐘳𐘦', 2), ('𐘭𐘷', 2), ('𐘆𐘦', 2), ('𐘅𐘚', 3), ('𐘇𐘙', 7), ('𐘞𐘁', 2), ('𐘸𐘠', 2), ('𐘚𐘳', 2), ('𐘤𐙀', 2), ('𐘤𐘘', 3), ('𐘳𐘀', 2), ('𐘲𐘻', 2), ('𐘣𐘱', 2), ('𐘇𐘱', 3), ('𐘚𐘸', 3), ('𐘢𐘻', 2), ('𐘅𐘐', 2), ('𐘭𐘶', 2), ('𐘢𐘠', 2), ('𐘉𐘆', 2), ('𐘾𐘸', 2), ('𐘗𐘻', 4), ('𐘥𐘤', 2), ('𐘤𐘝', 2), ('𐘭𐘀', 2), ('𐙂𐘻', 4), ('𐘍𐘈', 4), ('𐘸𐘳', 6), ('𐘭𐘦', 2), ('𐘿𐘤', 2), ('𐘇𐘂', 4), ('𐘅𐘹', 6), ('𐘚𐘠', 4), ('𐘀𐙂', 4), ('𐘳𐘱', 3), ('𐘯𐘠', 3), ('𐘳𐘥', 2), ('𐘝𐘾', 2), ('𐘠𐘍', 2), ('𐙓𐘬', 2), ('𐘂𐘚', 2), ('𐘝𐘻', 2), ('𐘇𐘳', 10), ('𐘤𐘚', 2), ('𐘻𐘱', 2), ('𐘰𐘝', 3), ('𐘯𐘈', 2), ('𐘚𐘾', 2), ('𐘇𐘭', 5), ('𐘬𐘻', 2), ('𐘸𐘆', 2), ('𐘈𐘱', 2), ('𐘱𐘈', 3), ('𐙁𐘠', 5), ('𐘅𐘙', 2), ('𐘲𐘫', 3), ('𐙅𐘤', 2), ('𐘸𐘴', 5), ('𐙂𐘈', 2), ('𐘀𐘚', 4), ('𐘚𐘞', 2), ('𐘞𐘘', 2), ('𐙂𐘝', 4), ('𐘶𐙂', 2), ('𐙂𐘹', 3), ('𐘆𐘱', 3), ('𐘚𐙀', 3), ('𐘻𐘯', 4), ('𐘗𐘤', 2), ('𐘐𐙈', 2), ('𐙂𐘳', 2), ('𐘅𐘱', 2), ('𐘠𐙂', 2), ('𐘴𐘙', 4), ('𐘇𐘅', 4), ('𐘘𐘞', 2), ('𐘰𐘅', 3), ('𐘾𐘂', 2), ('𐘱𐘻', 2), ('𐘯𐘃', 2), ('𐘘𐘾', 4), ('𐘾𐘁', 2), ('𐘅𐘤', 11), ('𐘻𐘍', 2), ('𐙂𐘰', 6), ('𐘈𐘤', 3), ('𐘱𐘞', 9), ('𐘴𐘆', 2), ('𐘾𐘙', 2), ('𐘬𐘜', 2), ('𐘴𐘹', 2), ('𐙁𐘙', 4), ('𐙂𐘶', 2), ('𐘳𐙁', 4), ('𐘀𐘉', 3), ('𐘚𐘀', 8), ('𐘦𐘻', 2), ('𐘙𐘳', 2), ('𐘈𐘗', 2), ('𐙕𐘮', 4), ('𐘀𐘰', 2), ('𐘤𐘅', 2), ('𐘀𐘙', 5), ('𐙁𐘚', 5), ('𐘿𐘠', 4), ('𐘭𐘝', 3), ('𐘇𐘞', 8), ('𐘢𐘃', 2), ('𐘃𐘥', 2), ('𐘸𐘞', 2), ('𐙂𐘘', 3), ('𐘆𐘭', 2), ('𐘭𐘤', 2), ('𐘬𐙁', 3), ('𐘇𐙁', 4), ('𐘇𐘾', 4), ('𐘙𐘆', 3), ('𐘆𐘀', 2), ('𐘸𐘈', 3), ('𐘇𐘧', 2), ('𐘹𐘂', 3), ('𐘞𐘭', 4), ('𐘅𐘇', 2), ('𐙝𐘭', 2), ('𐘘𐙁', 8), ('𐘹𐘗', 2), ('𐙂𐘠', 2), ('𐙈𐘻', 2), ('𐘂𐘌', 2), ('𐘤𐘸', 4), ('𐘱𐘸', 3), ('𐘤𐘹', 2), ('𐙂𐘢', 2), ('𐘲𐘸', 4), ('𐘃𐘹', 2), ('𐘭𐘃', 3), ('𐘠𐘬', 2), ('𐘲𐙁', 4), ('𐘱𐘆', 5), ('𐘴𐘭', 2), ('𐘸𐘤', 2), ('𐘹𐙁', 2), ('𐘀𐘳', 4), ('𐘱𐘳', 3), ('𐘐𐘭', 3), ('𐘴𐘗', 3), ('𐘱𐘲', 3), ('𐘳𐘧', 2), ('𐘤𐘾', 3), ('𐙀𐘆', 2), ('𐙁𐘃', 4), ('𐙁𐘭', 3), ('𐘀𐘶', 2), ('𐘇𐘠', 2), ('𐘞𐙁', 3), ('𐘳𐘅', 15), ('𐘭𐘱', 5), ('𐘇𐘤', 7), ('𐙱𐘍', 2), ('𐘝𐘍', 2), ('𐘳𐘢', 2), ('𐙂𐙀', 4), ('𐘹𐘋', 5), ('𐘾𐘭', 2), ('𐙁𐘳', 4), ('𐘆𐘗', 2), ('𐘙𐘃', 2), ('𐘞𐘱', 3), ('𐘣𐘞', 2), ('𐘂𐘞', 2), ('𐘝𐘱', 2), ('𐘦𐘍', 2), ('𐘱𐙁', 2), ('𐘙𐘇', 2), ('𐙕𐘉', 3), ('𐘌𐘠', 4), ('𐘝𐘳', 5), ('𐘆𐘝', 2), ('𐘝𐘃', 2), ('𐘿𐘽', 2), ('𐙀𐘅', 2), ('𐘿𐘹', 2), ('𐙁𐘘', 3), ('𐙀𐘭', 2), ('𐙂𐘅', 3), ('𐘱𐘮', 3), ('𐘤𐘱', 3), ('𐘇𐘰', 3), ('𐘚𐘅', 8), ('𐙠𐘚', 2), ('𐘱𐘚', 2), ('𐘙𐘞', 2), ('𐘅𐘴', 2), ('𐘀𐘬', 4), ('𐘚𐙂', 5), ('𐘇𐘘', 3), ('𐘻𐘸', 2), ('𐘱𐘢', 2), ('𐙀𐘮', 2), ('𐘬𐘗', 2), ('𐘯𐘝', 2), ('𐘇𐘴', 8), ('𐘀𐘀', 2), ('𐘀𐘴', 6), ('𐘅𐘘', 3), ('𐘅𐘬', 2), ('𐙂𐘴', 2), ('𐘭𐘻', 2), ('𐘞𐘴', 14), ('𐘀𐘝', 2), ('𐘆𐘤', 2), ('𐘅𐘠', 4), ('𐘳𐘙', 4), ('𐘇𐘸', 2), ('𐘚𐘬', 3), ('𐘤𐙈', 3), ('𐘸𐘯', 2), ('𐘳𐘗', 2), ('𐘌𐘞', 2), ('𐘸𐘙', 3), ('𐘉𐘅', 10), ('𐘯𐙁', 3), ('𐘸𐘦', 2), ('𐘠𐘀', 2), ('𐘅𐘲', 2), ('𐘂𐘳', 5), ('𐘻𐘗', 2)}\n",
      "\n",
      "Phaistos Disc Bigrams appearing in more than one word\n",
      "{('𐇬𐇳', 2), ('𐇧𐇷', 2), ('𐇦𐇨', 2), ('𐇮𐇩', 3), ('𐇱𐇦', 2), ('𐇜𐇐', 5), ('𐇶𐇰', 2), ('𐇦𐇡', 3), ('𐇐𐇡', 2), ('𐇪𐇨', 2), ('𐇕𐇲', 2), ('𐇕𐇡', 2), ('𐇧𐇣', 2), ('𐇖𐇗', 2), ('𐇛𐇜', 2), ('𐇢𐇲', 2), ('𐇑𐇛', 10), ('𐇛𐇪', 2), ('𐇼𐇖', 5), ('𐇬𐇱', 2), ('𐇪𐇼', 2), ('𐇳𐇖', 2), ('𐇷𐇖', 2)}\n"
     ]
    }
   ],
   "source": [
    "#print([(tr, la_trigrams.count(tr)) for tr in la_trigrams if la_trigrams.count(tr) > 1])\n",
    "\n",
    "print(\"Linear A Bigrams appearing in more than one word\")\n",
    "print(set((tr, la_bigrams_per_unique_word.count(tr)) for tr in la_bigrams_per_unique_word \n",
    "       if la_bigrams_per_unique_word.count(tr) > 1))\n",
    "\n",
    "print(\"\\nPhaistos Disc Bigrams appearing in more than one word\")\n",
    "print(set((tr, pd_bigrams_per_unique_word.count(tr)) for tr in pd_bigrams_per_unique_word \n",
    "       if pd_bigrams_per_unique_word.count(tr) > 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_la_map = {\n",
    "\"𐇐\": \"𐙇\",  \n",
    "\"𐇑\": \"\", \n",
    "\"𐇒\": \"\", \n",
    "\"𐇓\": \"\", \n",
    "\"𐇔\": \"\", \n",
    "\"𐇕\": \"𐚌\",  \n",
    "\"𐇖\": \"𐘠\",  \n",
    "\"𐇗\": \"𐘚\",  \n",
    "\"𐇘\": \"\", \n",
    "\"𐇙\": \"\", \n",
    "\"𐇚\": \"\", \n",
    "\"𐇛\": \"𐘿\",  \n",
    "\"𐇜\": \"\", \n",
    "\"𐇝\": \"𐘳\",  \n",
    "\"𐇞\": \"𐘊\",  \n",
    "\"𐇟\": \"𐘸\", \n",
    "\"𐇠\": \"\",  \n",
    "\"𐇡\": \"𐘠\",  \n",
    "\"𐇢\": \"𐘀\",  \n",
    "\"𐇣\": \"𐘗\",  \n",
    "\"𐇤\": \"𐘱\",  \n",
    "\"𐇥\": \"𐘞\",  \n",
    "\"𐇦\": \"𐘅\",  \n",
    "\"𐇧\": \"𐘦\",  \n",
    "\"𐇨\": \"𐙅\",  \n",
    "\"𐇩\": \"\", \n",
    "\"𐇪\": \"𐙒\",  \n",
    "\"𐇫\": \"\", \n",
    "\"𐇬\": \"𐙁\",  \n",
    "\"𐇭\": \"𐘏\", \n",
    "\"𐇮\": \"𐙂\",  \n",
    "\"𐇯\": \"𐘻\",  \n",
    "\"𐇰\": \"\", \n",
    "\"𐇱\": \"𐘢\",  \n",
    "\"𐇲\": \"𐘃\",  \n",
    "\"𐇳\": \"𐘝\",  \n",
    "\"𐇴\": \"\", \n",
    "\"𐇵\": \"\", \n",
    "\"𐇶\": \"\", \n",
    "\"𐇷\": \"𐘹\",  \n",
    "\"𐇸\": \"\", \n",
    "\"𐇹\": \"\", \n",
    "\"𐇺\": \"\", \n",
    "\"𐇻\": \"\", \n",
    "\"𐇼\": \"𐘽\", \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_syllables = {}\n",
    "input_file = open(\"../050-syllables.txt\", 'r')                                                                         \n",
    "while True:\n",
    "    line = input_file.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_array = (line.strip().replace(\"VINa\", \"VIN\").replace(\"-VS\", \"\")\n",
    "        .replace(\"+[?]\", \"\").replace(\"[\",\"\").split('\\t'))\n",
    "    if len(line_array) < 2:\n",
    "        continue\n",
    "    la_syllables[line_array[0]] = line_array[1]\n",
    "input_file.close()\n",
    "\n",
    "la = set(list(it.chain.from_iterable(la_bigrams)))\n",
    "la = filter(lambda x: x not in pd_la_map.values(), la)\n",
    "pd = list(filter(lambda x: pd_la_map[x] == \"\", pd_la_map.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the provisional PD to LA mapping above to find common bigrams between LA and the Disc\n",
    "pd_inscription_as_la = list(map(lambda x: pd_la_map[x] if x in pd_la_map and pd_la_map[x] != \"\" else x, pd_inscription))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['𐘢𐘅', '𐘸𐘅', '𐘿𐙂', '𐙁𐘢', '𐙁𐘽', '𐙁𐙁']\n"
     ]
    }
   ],
   "source": [
    "pd_inscription_as_la_words = ''.join(pd_inscription_as_la).split('|')\n",
    "pd_la_bigrams = getNgrams(pd_inscription_as_la_words,2)\n",
    "\n",
    "matching_bigrams = []\n",
    "for inscription in inscriptions:\n",
    "    word_tags = inscription[\"tagsForWords\"]\n",
    "\n",
    "    for index, word_tag in enumerate(word_tags):\n",
    "        tags = word_tag[\"tags\"]\n",
    "        if \"word\" not in tags:\n",
    "            continue\n",
    "        word = word_tag[\"word\"]\n",
    "        if len(word) == 1:\n",
    "            continue\n",
    "        for i in range(0, len(word) - 1):\n",
    "            bg = word[i:i+2]\n",
    "            if bg in pd_la_bigrams:\n",
    "                matching_bigrams.append(bg)\n",
    "                #print(bg, inscription[\"name\"], word, [w for w in pd_inscription_as_la_words if bg in w])\n",
    "sorted_matching_bigrams = sorted(set(matching_bigrams))\n",
    "print(sorted_matching_bigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['𐇧𐇧', '𐇪𐇪', '𐇬𐇬']\n",
      "{'𐘅𐘅', '𐘸𐘸', '𐝀𐝀', '𐝂𐝂', '𐘴𐘴', '𐝆𐝆', '𐘆𐘆', '𐙁𐙁', '||', '𐘌𐘌', '𐘤𐘤', '𐙕𐙕', '𐘳𐘳', '𐘱𐘱', '𐝈𐝈', '𐘀𐘀', '𐙍𐙍', '𐄐𐄐', '𐝁𐝁', '𐙂𐙂', '𐘃𐘃', '𐘠𐘠', '𐝃𐝃', '𐘞𐘞', '𐝏𐝏', '𐘰𐘰'}\n"
     ]
    }
   ],
   "source": [
    "# Find repeating syllabograms in PD and LA\n",
    "pd_rs = []\n",
    "for word in pd_words:\n",
    "    prev_letter = \"\"\n",
    "    for letter in word:\n",
    "        if letter == prev_letter:\n",
    "            pd_rs.append(letter + letter)\n",
    "        prev_letter = letter\n",
    "print(list(set(pd_rs)))\n",
    "\n",
    "la_rs = []\n",
    "for inscription in inscriptions:\n",
    "    word_tags = inscription[\"tagsForWords\"]\n",
    "\n",
    "    for word_tag in word_tags:\n",
    "        prev_letter = \"\"\n",
    "        word = word_tag[\"word\"].replace(u'\\U0001076b', \"\")\n",
    "        for letter in word:\n",
    "            if letter == prev_letter:\n",
    "                la_rs.append(letter + letter)\n",
    "            prev_letter = letter\n",
    "print(set(la_rs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'𐘠𐇡', '𐇸𐘀', '𐇑𐘿', '𐇙𐘅', '𐇣𐘃', '𐙁𐇰', '𐇡𐘃', '𐘅𐇵', '𐇪𐘃', '𐇡𐘠', '𐘠𐇜', '𐘚𐇽', '𐙅𐇵', '𐇕𐘃', '𐇩𐘿', '𐘅𐇔', '𐇣𐘿', '𐇻𐘚', '𐇷𐘃', '𐘿𐇓', '𐇪𐘢', '𐘿𐇯', '𐘃𐇽', '𐘚𐇜', '𐘿𐇸', '𐘞𐇷', '𐘠𐇽', '𐇷𐘿', '𐙁𐙁', '𐘃𐇯', '𐇴𐘅', '𐙂𐇩', '𐇰𐘅', '𐙁𐇧', '𐘠𐇧', '𐘸𐇝', '𐘝𐇷', '𐘿𐇕', '𐙅𐇙', '𐇪𐘽', '𐇞𐘠', '𐇪𐙅', '𐇷𐘠', '𐘿𐇪', '𐇠𐘀', '𐙅𐇪', '𐘞𐇴', '𐇹𐙅', '𐇩𐘝', '𐘃𐇴', '𐇯𐘅', '𐘿𐇜', '𐇩𐘃', '𐘅𐇡'}\n",
      "23 ['𐘀𐘃', '𐘃𐘅', '𐘅𐘀', '𐘅𐘠', '𐘅𐙅', '𐘝𐘠', '𐘞𐙁', '𐘞𐙅', '𐘠𐘃', '𐘠𐘅', '𐘠𐘚', '𐘠𐘽', '𐘠𐘿', '𐘢𐘅', '𐘸𐘅', '𐘽𐘠', '𐘿𐘞', '𐘿𐙂', '𐙁𐘚', '𐙁𐘝', '𐙁𐘢', '𐙁𐘽', '𐙁𐙁']\n",
      "{'𐇴', '𐇔', '𐇸', '𐇠', '𐇣', '𐇜', '𐇻', '𐇧', '𐇷', '𐇰', '𐇕', '𐇙', '𐇝', '𐇪', '𐇑', '𐇞', '𐇵', '𐇡', '𐇹', '𐇽', '𐇩', '𐇓', '𐇯'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Brent Davis 2018 mapping\n",
    "pd_la_strong_map = {\n",
    "\"𐇛\": \"𐘿\",  \n",
    "\"𐇬\": \"𐙁\",  \n",
    "\"𐇼\": \"𐘽\", \n",
    "\"𐇖\": \"𐘠\",  \n",
    "\"𐇱\": \"𐘢\",  \n",
    "\"𐇗\": \"𐘚\",  \n",
    "\"𐇮\": \"𐙂\",  \n",
    "\"𐇲\": \"𐘃\",  \n",
    "\"𐇢\": \"𐘀\",  \n",
    "\"𐇦\": \"𐘅\",  \n",
    "\"𐇨\": \"𐙅\",  \n",
    "\"𐇥\": \"𐘞\",  \n",
    "\"𐇟\": \"𐘸\", \n",
    "\"𐇳\": \"𐘝\",  \n",
    "}\n",
    "# My map\n",
    "pd_la_strong_map = {\n",
    "\"𐇑\": \"𐘚\", \n",
    "\"𐇛\": \"𐙀\",  \n",
    "\"𐇬\": \"𐙁\",  \n",
    "\"𐇼\": \"𐘽\", \n",
    "\"𐇖\": \"𐘠\",  \n",
    "\"𐇱\": \"𐘢\",  \n",
    "\"𐇮\": \"𐙂\",  \n",
    "\"𐇲\": \"𐘃\",  \n",
    "\"𐇢\": \"𐘀\",  \n",
    "\"𐇦\": \"𐘅\",  \n",
    "\"𐇨\": \"𐙅\",  \n",
    "\"𐇥\": \"𐘞\",  \n",
    "\"𐇟\": \"𐘸\", \n",
    "\"𐇳\": \"𐘝\",  \n",
    "}\n",
    "\"\"\"\n",
    "# My map\n",
    "pd_la_strong_map = {\n",
    "\"𐇗\": \"𐘚\",  \n",
    "\"𐇛\": \"𐘿\",  \n",
    "\"𐇬\": \"𐙁\",  \n",
    "\"𐇼\": \"𐘽\", \n",
    "\"𐇖\": \"𐘠\",  \n",
    "\"𐇱\": \"𐘢\",  \n",
    "\"𐇮\": \"𐙂\",  \n",
    "\"𐇲\": \"𐘃\",  \n",
    "\"𐇢\": \"𐘀\",  \n",
    "\"𐇦\": \"𐘅\",  \n",
    "\"𐇨\": \"𐙅\",  \n",
    "\"𐇥\": \"𐘞\",  \n",
    "\"𐇟\": \"𐘸\", \n",
    "\"𐇳\": \"𐘝\",  \n",
    "}\n",
    "\n",
    "#print(list(set(it.chain.from_iterable(la_bigrams))))\n",
    "#print(list(set(it.chain.from_iterable(pd_bigrams))))\n",
    "\n",
    "# Use the provisional PD to LA mapping above to find common bigrams between LA and the Disc\n",
    "pd_inscription_as_la = list(map(lambda x: pd_la_strong_map[x] if x in pd_la_strong_map else x, pd_inscription))\n",
    "pd_inscription_as_la_words = ''.join(pd_inscription_as_la).split('|')\n",
    "pd_la_bigrams = getNgrams(pd_inscription_as_la_words,2)\n",
    "\n",
    "#print(set([bg for bg in pd_bigrams for g in bg if g in pd_la_strong_map.keys()]))\n",
    "#print(set([bg for bg in la_bigrams for g in bg if g in pd_la_strong_map.values()]))\n",
    "\n",
    "# pd bigrams where just one symbol has a strong mapping\n",
    "pd_bigrams_one = set([bg for bg in pd_la_bigrams if len(set(pd_la_strong_map.values()) & set(bg)) == 1])\n",
    "print(pd_bigrams_one)\n",
    "pd_bigrams_both = set([bg for bg in pd_la_bigrams if all(g in pd_la_strong_map.values() for g in bg)])\n",
    "print(len(pd_bigrams_both), sorted(pd_bigrams_both))\n",
    "\n",
    "pd_symbols_with_mapping_clue = set([g for g in it.chain.from_iterable(pd_bigrams_one) if g not in la_symbols])\n",
    "print(pd_symbols_with_mapping_clue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'𐘅𐘱', '𐘅𐘐', '𐘅𐘗', '𐘅𐙁', '𐘅𐘝', '𐘅𐘅', '𐘅𐘿', '𐘅𐘹', '𐘅𐘾', '𐘅𐘉', '𐘅𐘮', '𐘅𐘻', '𐘅𐘠', '𐘅𐘘', '𐘅𐘤', '𐘅𐘯', '𐘅𐘂', '𐘅𐘽', '𐘅𐘀', '𐘅𐘙', '𐘅𐘚', '𐘅𐘃', '𐘅𐘲', '𐘅𐘬', '𐘅𐘸', '𐘅𐘴', '𐘅𐘁', '𐘅𐘳', '𐘅𐘇'}\n",
      "{'𐘸𐘅', '𐘚𐘅', '𐘳𐘅', '𐘮𐘅', '𐘨𐘅', '𐘴𐘅', '𐘰𐘅', '𐘅𐘅', '𐙀𐘅', '𐘡𐘅', '𐘜𐘅', '𐘣𐘅', '𐘠𐘅', '𐘾𐘅', '𐘞𐘅', '𐘀𐘅', '𐙕𐘅', '𐙯𐘅', '𐘤𐘅', '𐘈𐘅', '𐙂𐘅', '𐘻𐘅', '𐘁𐘅', '𐘢𐘅', '𐘝𐘅', '𐘭𐘅', '𐘂𐘅', '𐘇𐘅', '𐘙𐘅', '𐘉𐘅', '𐘘𐘅', '𐘹𐘅', '𐘆𐘅'}\n",
      "{'𐘅𐇔', '𐘅𐇵', '𐘅𐇢', '𐘅𐇖', '𐘅𐙅', '𐘅𐇡'}\n",
      "{'𐇖𐘅', '𐇴𐘅', '𐘸𐘅', '𐇯𐘅', '𐘃𐘅', '𐇰𐘅', '𐘢𐘅', '𐇙𐘅'}\n",
      "{'𐘅𐙅', '𐘃𐘅', '𐘸𐘅', '𐘢𐘅'}\n"
     ]
    }
   ],
   "source": [
    "la_symbol = '𐘅'\n",
    "print(set([bg for bg in la_bigrams if bg[:1] == la_symbol]))\n",
    "print(set([bg for bg in la_bigrams if bg[1:2] == la_symbol]))\n",
    "print(set([bg for bg in pd_la_bigrams if bg[:1] == la_symbol]))\n",
    "print(set([bg for bg in pd_la_bigrams if bg[1:2] == la_symbol]))\n",
    "print(set([bg for bg in pd_bigrams_both if la_symbol in bg]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped bigrams that actually appear in Linear A\n",
      " 16 [('𐘀𐘃', 2), ('𐘅𐘀', 1), ('𐘅𐘠', 4), ('𐘝𐘠', 1), ('𐘞𐙁', 3), ('𐘠𐘃', 1), ('𐘠𐘅', 2), ('𐘠𐘽', 2), ('𐘢𐘅', 2), ('𐘸𐘅', 2), ('𐘽𐘠', 1), ('𐘿𐙂', 1), ('𐙁𐘚', 5), ('𐙁𐘢', 1), ('𐙁𐘽', 1), ('𐙁𐙁', 1)]\n",
      "Mapped bigrams that don't appear in Linear A {'𐘅𐙅', '𐘠𐘿', '𐘃𐘅', '𐙁𐘝', '𐘿𐘞', '𐘞𐙅', '𐘠𐘚'}\n"
     ]
    }
   ],
   "source": [
    "bg_both = sorted([(bg, la_bigrams.count(bg)) for bg in pd_bigrams_both & set(la_bigrams)])\n",
    "print(\"Mapped bigrams that actually appear in Linear A\\n\", \n",
    "     len(bg_both), bg_both)\n",
    "print(\"Mapped bigrams that don't appear in Linear A\", \n",
    "      pd_bigrams_both - set(la_bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "def product(*args, repeat=1):\n",
    "    # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy\n",
    "    # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111\n",
    "    pools = [tuple(pool) for pool in args] * repeat\n",
    "    result = [[]]\n",
    "    for pool in pools:\n",
    "        result = [x+[y] for x in result for y in pool]\n",
    "    for prod in result:\n",
    "        yield tuple(prod)\n",
    "        \n",
    "t1 = [\"𐇐\", \"𐇑\", \"𐇒\" ]\n",
    "t2 = [\"𐄂\", \"𐘀\", \"𐘁\", \"𐘂\"]\n",
    "\n",
    "#len(list(list(zip(t1, item)) for item in it.product(t2, repeat=len(t1))))\n",
    "\n",
    "# This gives us (len(t2)! - (t2 - t1)!) mappings\n",
    "def getMap(t1, t2):\n",
    "    for item in it.product(t2, repeat=len(t1)):\n",
    "        if len(item) != len(set(item)):\n",
    "            continue\n",
    "        yield list(zip(t1, item))\n",
    "\n",
    "print(len(list(getMap(t1, t2))))\n",
    "\n",
    "#for combo in getMap(t1, t2):\n",
    "#   print(combo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3075990524006400.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "print(math.factorial(40) / math.factorial(30))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
